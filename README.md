# ğŸš€ LLM API Base Code

FastAPI-based LLM API with logging system, request tracing, and multi-provider support.

## âœ¨ Features

- ğŸ”¥ **FastAPI** - Modern, fast web framework
- ğŸ“ **Advanced Logging** - Request ID tracing, file rotation
- ğŸŒ **CORS Support** - Cross-origin resource sharing
- ğŸ”Œ **Multi-LLM Providers** - OpenAI, Anthropic, Gemini
- ğŸ›¡ï¸ **Type Safety** - Pydantic models
- ğŸ“Š **Request Tracing** - Unique ID for each request

## ğŸ—ï¸ Project Structure

```
app/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # Application settings
â”‚   â”œâ”€â”€ logging.py         # Logging configuration
â”‚   â””â”€â”€ middleware.py      # Request ID middleware
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ chat.py           # Chat endpoints
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ chat.py           # Pydantic models
â”œâ”€â”€ services/
â”‚   â””â”€â”€ __init__.py       # Business logic services
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log           # Application logs
â””â”€â”€ main.py               # FastAPI application
requirements.txt          # Python dependencies
README.md                 # Project documentation
.gitignore               # Git ignore rules
```

## ğŸš€ Quick Start

### 1. Clone repository
```bash
git clone https://github.com/Quoccuong1004/basecode.git
cd new-basecode
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Environment setup
```bash
cp .env.example .env
# Edit .env with your API keys
```

### 4. Run application
```bash
# Development
cd app
python3 -m main.py

# Or with uvicorn
cd app
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 5. Access API
- **API Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ“Š Logging Features

### Request Tracing
Each request gets a unique ID (3-4 characters) for log tracing:
```
2025-07-02 15:08:48 [ABC1] - LLM API Base.middleware - INFO - GET /health
2025-07-02 15:08:48 [ABC1] - LLM API Base.api - INFO - Health check processing
```

### Log Outputs
- **Console**: Real-time logs with colors
- **File**: `logs/app.log` with rotation (10MB max, 3 backups)
- **Headers**: Request ID in response headers

## ğŸ› ï¸ Development

### Run in development mode
```bash
python3 -m app.main
```

### Testing endpoints
```bash
# Health check
curl http://localhost:8000/health

# Root endpoint
curl http://localhost:8000/
```

## ğŸ“ API Endpoints

### Health
- `GET /` - Root endpoint
- `GET /health` - Health check

### Chat (Coming Soon)
- `POST /api/chat` - Chat completion
- `POST /api/completion` - Text completion
- `POST /api/embedding` - Text embedding

## ğŸ”„ Request Flow

1. **Request** â†’ RequestIDMiddleware generates unique ID
2. **Context** â†’ Request ID stored in context variable
3. **Processing** â†’ Endpoints process with logging
4. **Response** â†’ Request ID in headers
5. **Logs** â†’ All logs include request ID for tracing

## ğŸ† Best Practices

- âœ… Request ID tracing for debugging
- âœ… Structured logging with timestamps
- âœ… Environment-based configuration
- âœ… Type hints everywhere
- âœ… Error handling with proper status codes
- âœ… CORS configuration
- âœ… Hot reload for development

## ğŸ“ License

MIT License - feel free to use for your projects!

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

---

Built with â¤ï¸ using FastAPI and Python
